<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-06-15T16:32:47-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Curie Blog</title><author><name>Amber Liu</name></author><entry><title type="html">Can AI Conduct AI Research Experiments?</title><link href="http://localhost:4000/machine-learning/research/2025-06-11-exp-bench-can-ai-conduct-ai-research-experiments.html" rel="alternate" type="text/html" title="Can AI Conduct AI Research Experiments?" /><published>2025-06-11T00:00:00-07:00</published><updated>2025-06-11T00:00:00-07:00</updated><id>http://localhost:4000/machine-learning/research/exp-bench-can-ai-conduct-ai-research-experiments</id><content type="html" xml:base="http://localhost:4000/machine-learning/research/2025-06-11-exp-bench-can-ai-conduct-ai-research-experiments.html">&lt;!-- bundle exec jekyll serve --&gt;

&lt;div style=&quot;text-align: center; color: gray;&quot;&gt;

&lt;/div&gt;

&lt;div style=&quot;text-align: center&quot;&gt;


&lt;p style=&quot;font-size: 0.8em; color: grey;&quot;&gt;
  &lt;a href=&quot;https://www.cs-pk.com/&quot;&gt;Patrick Tser Jern Kon&lt;/a&gt;&lt;sup&gt;*&lt;/sup&gt;, 
  &lt;a href=&quot;https://websites.umich.edu/~amberljc/&quot;&gt;Jiachen Liu&lt;/a&gt;&lt;sup&gt;*&lt;/sup&gt; (Equal Contribution&lt;sup&gt;*&lt;/sup&gt;)&lt;br /&gt;
  Xinyi Zhu,
  Qiuyi Ding, 
  &lt;a href=&quot;https://www.linkedin.com/in/jingjia-peng/&quot;&gt;Jingjia Peng&lt;/a&gt; (University of Michigan),  
  &lt;a href=&quot;https://jxing.me/&quot;&gt;Jiarong Xing&lt;/a&gt; (UC Berkeley &amp;amp; Rice University), 
  &lt;a href=&quot;https://huangyibo.github.io/&quot;&gt;Yibo Huang&lt;/a&gt; (University of Michigan), 
  &lt;a href=&quot;https://yimingqiu.me/&quot;&gt;Yiming Qiu&lt;/a&gt; (UC Berkeley &amp;amp; University of Michigan), 
  &lt;a href=&quot;https://scholar.google.com/citations?user=HtNfeKYAAAAJ&amp;amp;hl=en&quot;&gt;Jayanth Srinivasa&lt;/a&gt;,
  &lt;a href=&quot;https://www.linkedin.com/in/myungjin-lee-5308136/&quot;&gt;Myungjin Lee&lt;/a&gt; (Cisco Research), &lt;br /&gt;
  &lt;a href=&quot;https://www.mosharaf.com/&quot;&gt;Mosharaf Chowdhury&lt;/a&gt; (University of Michigan), 
  &lt;a href=&quot;https://stanford.edu/~matei/&quot;&gt;Matei Zaharia&lt;/a&gt; (UC Berkeley), 
  &lt;a href=&quot;https://web.eecs.umich.edu/~chenang/&quot;&gt;Ang Chen&lt;/a&gt; (University of Michigan)
&lt;/p&gt;


&lt;a href=&quot;https://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench&quot;&gt; üìä Dataset&lt;/a&gt; | 
&lt;a href=&quot;https://arxiv.org/abs/2505.24785&quot;&gt;üìÑ Paper&lt;/a&gt; | &lt;a href=&quot;https://github.com/Just-Curieous/Curie&quot;&gt;üíª Github&lt;/a&gt; 
&lt;/div&gt;

&lt;p&gt;AI for Science is rapidly advancing, with promising early work on scientific automation‚Äîsuch as DeepMind‚Äôs &lt;a href=&quot;https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/&quot;&gt;AlphaEvolve&lt;/a&gt; and others highlighted in this Nature &lt;a href=&quot;https://www.nature.com/articles/s41586-023-06221-2&quot;&gt;paper&lt;/a&gt;.
A particularly exciting frontier is &lt;strong&gt;the automation of AI research experimentation&lt;/strong&gt;‚Äîthe process of designing, executing, and analyzing experiments to advance AI itself. Unlike fields requiring physical experimentation, AI research is largely digital‚Äîwell-suited for LLM-based automation.&lt;/p&gt;

&lt;p&gt;Ideally, we want to provide an AI agent with a research goal‚Äîsuch as reproducing a result, validating a new hypothesis, or testing an ablation‚Äî along with the specific context and have the agent:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Formulate hypotheses, design experiments,&lt;/li&gt;
  &lt;li&gt;Interpret the associated codebase and identify how to modify it,&lt;/li&gt;
  &lt;li&gt;Configure and execute experiments under the right conditions,&lt;/li&gt;
  &lt;li&gt;Analyze results and iteratively refine its approach based on findings&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center; max-width: 800px; margin: 0 auto; padding: 0 15px;&quot;&gt;
    &lt;img src=&quot;/assets/images/exp-bench-overview.png&quot; alt=&quot;EXP-Bench Overview&quot; style=&quot;width: 100%; height: auto; display: block; margin: 0 auto;&quot; /&gt;
    &lt;p style=&quot;font-size: 0.8em; margin-top: 10px; color: grey;&quot;&gt;
        Figure 1. EXP-Bench evaluates AI agents on research experiment tasks extracted semi-autonomously from peer-reviewed AI papers.
    &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Achieving this vision requires benchmarks that evaluate agents in real-world research scenarios. But how do we define those scenarios in a way that‚Äôs representative, reproducible, and gradable?&lt;/p&gt;

&lt;p&gt;Intuitively, peer-reviewed AI papers (e.g., in NeurIPS) along with their open-source codebases, offer a rich source of completed experiments that could, in theory, be repurposed to evaluate AI capabilities in research automation. In practice, however, extracting these tasks is difficult. Papers often present a polished narrative that omits intermediate steps, while critical details‚Äîsuch as the precise conditions under which results hold‚Äîare scattered across dense text, supplementary materials, and sprawling repositories.&lt;/p&gt;

&lt;h2 id=&quot;our-contribution-exp-bench&quot;&gt;Our Contribution: EXP-Bench&lt;/h2&gt;

&lt;p&gt;To address this challenge, we introduce &lt;strong&gt;EXP-Bench&lt;/strong&gt;, a new benchmark designed to make the ever-expanding landscape of published research more accessible for evaluating AI agents in &lt;strong&gt;conducting end-to-end research experiments&lt;/strong&gt;‚Äîfrom hypothesis to experimental setup to conclusion, as shown in Figure 1. We develop a semi-automated pipeline that uses multimodal and agentic approaches to reconstruct experiments from fragmented and dense sources (e.g., coding agents identify setups by conditioning on ground-truth outcomes and leveraging the full codebase‚Äîreducing the task to a constrained search), while interleaving these steps with lightweight human validation to ensure correctness.&lt;/p&gt;

&lt;p&gt;Using this approach, we distilled &lt;em&gt;461 experiments from NeurIPS and ICLR papers&lt;/em&gt;‚Äîspanning domains such as vision, RL, and computational biology‚Äîresulting in over 12,000 gradable subtasks.&lt;/p&gt;

&lt;div style=&quot;text-align: center; max-width: 800px; margin: 0 auto; padding: 0 15px;&quot;&gt;
    &lt;img src=&quot;/assets/images/exp-construction.png&quot; alt=&quot;EXP-Bench Construction&quot; style=&quot;width: 100%; height: auto; display: block; margin: 0 auto;&quot; /&gt;
    &lt;p style=&quot;font-size: 0.8em; margin-top: 10px; color: grey;&quot;&gt;
        Figure 2. Our semi-automated pipeline for constructing EXP-Bench from published papers.
    &lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;what-exp-bench-reveals-about-todays-ai-agents&quot;&gt;What EXP-Bench Reveals About Today‚Äôs AI Agents&lt;/h2&gt;

&lt;p&gt;We tested leading agents, including &lt;em&gt;OpenHands w/ Claude Sonnet 3.7&lt;/em&gt;, and found that while they can earn partial credit for individual steps like experiment design or coding (~20-35% success), their ability to &lt;em&gt;complete a full, executable experiment&lt;/em&gt; is nearly non-existent‚Äîa mere 0.5% success rate.
Our analysis pinpointed several critical weaknesses:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Limited Long-Horizon Planning and Reasoning&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Inability to Handle Open-Ended and Ambiguous Tasks&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Difficulty with Code Execution and Debugging&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These results highlight just how far we still are from our goal of automation of research experimentation. By identifying these bottlenecks and providing realistic step-by-step experiment procedures, EXP-Bench serves as a vital tool for future AI agents to improve their ability to conduct AI research experiments.&lt;/p&gt;

&lt;h2 id=&quot;looking-forward&quot;&gt;Looking Forward&lt;/h2&gt;

&lt;p&gt;This work is, we hope, a small step toward our broader goal of designing agents capable of automating scientific research. We see EXP-Bench as a launchpad for the next wave of AI research copilots.&lt;/p&gt;

&lt;p&gt;That said, much work remains. While EXP-Bench currently focuses on machine learning papers, it does not yet address domains that require interaction with the physical world or support tasks involving true scientific invention. Expanding to those areas‚Äîand capturing the creativity, uncertainty, and iteration of real-world discovery‚Äîremains an open and exciting challenge.&lt;/p&gt;

&lt;h2 id=&quot;explore-our-work&quot;&gt;Explore Our Work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;üìë &lt;a href=&quot;https://arxiv.org/abs/2505.24785&quot;&gt;Full paper&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;üóÉÔ∏è &lt;a href=&quot;https://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench&quot;&gt;Open-sourced dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bib highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;@article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;kon2025expbenchaiconductai&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{EXP-Bench: Can AI Conduct AI Research Experiments?}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;na&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{Patrick Tser Jern Kon and Jiachen Liu and Xinyi Zhu and Qiuyi Ding and Jingjia Peng and Jiarong Xing and Yibo Huang and Yiming Qiu and Jayanth Srinivasa and Myungjin Lee and Mosharaf Chowdhury and Matei Zaharia and Ang Chen}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;journal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{arXiv preprint 2505.24785}&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;={2025&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;[1] MogaNet: Multi-order Gated Aggregation Network. ICLR 2024&lt;/em&gt;&lt;/p&gt;</content><author><name>Amber Liu</name></author><category term="machine-learning" /><category term="research" /><summary type="html"></summary></entry><entry><title type="html">The MLE Agent for Your Research</title><link href="http://localhost:4000/machine-learning/research/2025-05-27-automl-co-scientist.html" rel="alternate" type="text/html" title="The MLE Agent for Your Research" /><published>2025-05-27T00:00:00-07:00</published><updated>2025-05-27T00:00:00-07:00</updated><id>http://localhost:4000/machine-learning/research/automl-co-scientist</id><content type="html" xml:base="http://localhost:4000/machine-learning/research/2025-05-27-automl-co-scientist.html">&lt;div style=&quot;text-align: center; color: gray;&quot;&gt;
&lt;h2 style=&quot;font-size: 1.15em; color: grey;&quot;&gt;The AI Co-Scientist Making ML More Accessible for Your Research&lt;/h2&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center&quot;&gt;
&lt;a href=&quot;https://github.com/Just-Curieous/Curie&quot;&gt;üíª Github Link&lt;/a&gt; | &lt;a href=&quot;https://github.com/Just-Curieous/Curie/tree/main/benchmark/mle_bench&quot;&gt; üìí Use Cases&lt;/a&gt; | 
&lt;a href=&quot;https://arxiv.org/abs/2502.16069&quot;&gt;üìÑ Paper Link&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;In our previous &lt;a href=&quot;https://www.just-curieous.com/&quot;&gt;post&lt;/a&gt;, we introduced &lt;a href=&quot;https://github.com/Just-Curieous/Curie&quot;&gt;Curie&lt;/a&gt;: an open-sourced AI co-scientist that automates experimentation and accelerate the journey from idea to validation. Today, we‚Äôre thrilled to introduce Curie‚Äôs AutoML feature, designed to help researchers &lt;strong&gt;rapidly test hypotheses&lt;/strong&gt; and unlock insights from their &lt;strong&gt;valuable data&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We built this AutoML feature after personally seeing how even highly-capable researchers‚Äîin fields like biology, materials science, and chemistry‚Äîstruggle to apply machine learning to their work. They often have valuable data, but lack the advanced ML knowledge to fully explore its potential. 
Despite their expertise, the technical barriers make ML feel out of reach, and this is the exact problem that we wanted to solve. Curie can create end-to-end machine learning solutions for non-ML experts, and we have evidence of it already making a positive impact with our early adopters.&lt;/p&gt;

&lt;h3 id=&quot;introducing-curies-new-feature-your-automated-ml-solution&quot;&gt;Introducing Curie‚Äôs New Feature: Your Automated ML Solution&lt;/h3&gt;

&lt;p&gt;Curie goes beyond traditional parameter or architecture search based AutoML, and takes over all the tedious but critical work performed by ML practitioners.&lt;/p&gt;

&lt;p&gt;From data preprocessing, to model and hyperparameter selection, to training and deploying recipes, which all require deep expertise. It‚Äôs a &lt;strong&gt;vast search space&lt;/strong&gt; to find the best performing solution, often involving &lt;strong&gt;iterative experiments&lt;/strong&gt; and &lt;strong&gt;specialized intuition&lt;/strong&gt; to fine-tune all the different components in the pipeline. Curie aims to automate this. The goal is to democratize access to powerful ML capabilities for researchers.&lt;/p&gt;

&lt;div class=&quot;figure-container&quot; style=&quot;text-align: center; margin: 20px 0;&quot;&gt;
    &lt;img src=&quot;/assets/exp-bench-mle-curie.drawio.png&quot; alt=&quot;Curie AutoML Overview&quot; style=&quot;width: 80%; height: auto; max-width: 100%;&quot; /&gt;
    &lt;div style=&quot;margin-top: 10px; font-style: italic; color: #666; font-size: 14px;&quot;&gt;
        Curie AutoML Overview
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;All you need to do is input your research question and the dataset path to Curie (more details &lt;a href=&quot;https://github.com/Just-Curieous/Curie&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;curie&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;curie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;api_keys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;E.g. How to improve my prediction accuracy on my dataset. Checkout &amp;lt;paper.pdf&amp;gt; for the more information.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;workspace_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Optional] /path/to/your/code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dataset_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/path/to/your/dataset&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From there, it will work to generate the optimal ML solution for your specific problem given the budget.&lt;/p&gt;

&lt;h3 id=&quot;curie-in-action-demonstrated-performance&quot;&gt;Curie in Action: Demonstrated Performance&lt;/h3&gt;

&lt;p&gt;We‚Äôve benchmarked Curie on several ML tasks‚Äîincluding several from &lt;a href=&quot;https://github.com/openai/mle-bench/&quot;&gt;MLE-Bench&lt;/a&gt;‚Äîto demonstrate its capabilities:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Just-Curieous/Curie/blob/main/benchmark/mle_bench/siim-isic-melanoma-classification&quot;&gt;Identifying Melanoma (Cancer) in Images of Skin Lesions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Just-Curieous/Curie/blob/main/benchmark/mle_bench/aptos2019-blindness-detection&quot;&gt;Predict the severity level of diabetic retinopathy based on retinal images&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Just-Curieous/Curie/tree/main/benchmark/mle_bench/histopathologic-cancer-detection&quot;&gt;Histopathologic Cancer Detection&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Just-Curieous/Curie-Use-Cases/tree/main/stock_prediction&quot;&gt;Stock Price Prediction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More AutoML use cases can be found &lt;a href=&quot;https://github.com/Just-Curieous/Curie-Use-Cases&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;case-study-skin-cancer-detection-challenge&quot;&gt;Case Study: Skin Cancer Detection Challenge&lt;/h4&gt;
&lt;p&gt;Here‚Äôs a preview of an auto-generated report from Curie. You can scroll through it to see the detailed analysis and insights:&lt;/p&gt;

&lt;iframe src=&quot;/assets/report.pdf&quot; width=&quot;100%&quot; height=&quot;600px&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Curie demonstrated some impressive capabilities in the skin cancer detection challenge:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It managed to train a model achieving &lt;strong&gt;a remarkable 0.99 AUC (top 1% performance)&lt;/strong&gt; using 2 hours. Moreover, the agent intelligently explored a variety of models with early stopping strategies on dataset subsets to quickly gauge potential to &lt;strong&gt;efficiently navigate the vast search space&lt;/strong&gt; of possible models.&lt;/li&gt;
  &lt;li&gt;It incorporated data augmentation (random rotation, color jitter, ‚Ä¶) to enhance model generalization.&lt;/li&gt;
  &lt;li&gt;It provided detailed analysis on performance versus system trade-offs, offering insights for efficient model deployment strategies.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Despite the strong performance, there are areas where Curie can evolve.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The current model architectures explored were relatively basic, and the specific ML problem, while important, is a well-established one. It‚Äôs possible the task wasn‚Äôt as challenging as some newer, more complex problems. The true test will be its performance on more diverse, real-world datasets.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Looking ahead, a crucial area for improvement lies in enhancing the agent‚Äôs hypothesis generation capabilities. We‚Äôre keen to see it explore the search space beyond established empirical knowledge, which will be key to unlocking even higher levels of accuracy and tackling more novel challenges.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;join-us--contribute-to-open-science&quot;&gt;Join Us &amp;amp; Contribute to Open Science&lt;/h3&gt;

&lt;p&gt;And this is where we need your help! We believe in open science, and your usage of Curie will help us make it better and support more scientists. We also welcome contributions to our &lt;a href=&quot;https://github.com/Just-Curieous/Curie/tree/main&quot;&gt;repo&lt;/a&gt;, we can‚Äôt keep up with all the latest research by ourselves!&lt;/p&gt;

&lt;!-- ## Performance Visualizations

Here are some visualizations showcasing Curie's performance on various tasks: --&gt;

&lt;!-- ![Model Performance Metrics](/assets/output-1.png)
*Figure 1: Comprehensive performance metrics across different model configurations*

![Training Progress](/assets/output-2.png)
*Figure 2: Training progress and convergence analysis*

![Model Comparison](/assets/output-3.png)
*Figure 3: Comparative analysis of different model architectures*

![Feature Importance](/assets/output-4.png)
*Figure 4: Feature importance analysis and insights*

![Performance Distribution](/assets/output-5.png)
*Figure 5: Distribution of model performance across different test cases*  --&gt;

&lt;!-- - The agent accurately identified critical class imbalances within the APTOS 2019 dataset. --&gt;
&lt;!-- Cool Factor: It smartly discovered that CLAHE enhancement significantly improved performance by clarifying subtle retinal features crucial for diagnosis. --&gt;

&lt;div class=&quot;language-bib highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;@misc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;kon2025curierigorousautomatedscientific&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;na&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{Patrick Tser Jern Kon and Jiachen Liu and Qiuyi Ding and Yiming Qiu and Zhenning Yang and Yibo Huang and Jayanth Srinivasa and Myungjin Lee and Mosharaf Chowdhury and Ang Chen}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{2025}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;eprint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{2502.16069}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;archivePrefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{arXiv}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;primaryClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{cs.AI}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Amber Liu</name></author><category term="machine-learning" /><category term="research" /><summary type="html">The AI Co-Scientist Making ML More Accessible for Your Research</summary></entry></feed>